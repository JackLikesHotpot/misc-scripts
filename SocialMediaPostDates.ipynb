{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0029bbe",
   "metadata": {},
   "source": [
    "# Social Media Post Dates\n",
    "#### Goes through a spreadsheet of Reddit/Twitter links and generates a Date column containing the dates of when those links were generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2520f2c",
   "metadata": {},
   "source": [
    "### Pandas initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8560c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd823c0",
   "metadata": {},
   "source": [
    "### Twitter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d67b0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Crawl to get creation date of post using ID of tweet\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "bearer_token =\"<TWITTER_BEARER_TOKEN>\"\n",
    "\n",
    "class TwitterCrawl:\n",
    "    def create_url(self, ids):\n",
    "        tweet_fields = \"tweet.fields=created_at,author_id\"\n",
    "        url = \"https://api.twitter.com/2/tweets?ids={}&{}\".format(ids, tweet_fields)\n",
    "        return url\n",
    "\n",
    "\n",
    "    def bearer_oauth(self, r):\n",
    "        \"\"\"\n",
    "        Method required by bearer token authentication.\n",
    "        \"\"\"\n",
    "        r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "        r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "        return r\n",
    "\n",
    "    def connect_to_endpoint(self, url):\n",
    "        response = requests.request(\"GET\", url, auth=self.bearer_oauth)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                \"Request returned an error: {} {}\".format(\n",
    "                    response.status_code, response.text\n",
    "                )\n",
    "            )\n",
    "        return response.json()\n",
    "\n",
    "    def main(self, ids):\n",
    "        url = self.create_url(ids)\n",
    "        json_response = self.connect_to_endpoint(url)\n",
    "        return(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e327",
   "metadata": {},
   "source": [
    "### Reddit initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b79fb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PRAW for Reddit crawl\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"<REDDIT_CLIENT_ID>\",\n",
    "    client_secret=\"<REDDIT_CLIENT_SECRET>\",\n",
    "    user_agent=\"<REDDIT_USER_AGENT>\",\n",
    "    redirect_uri=\"<REDIRECT_URI>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd939a",
   "metadata": {},
   "source": [
    "### Iteration process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4d9830cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through each row to get the tweet/post's date of creation and assign it into the column.\n",
    "\n",
    "def iterateThroughDF(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if 'twitter' in row['Link'].lower():\n",
    "            post = tCrawl.main(row['Link'].split('/')[-1])\n",
    "            df.at[index, 'Date'] = (post['data'][0]['created_at'].split('T')[0])\n",
    "        if 'reddit' in row['Link'].lower():\n",
    "            value = dt.fromtimestamp(reddit.submission(row['Link'].split('/')[-3]).created)\n",
    "            df.at[index, 'Date'] = f\"{value:%Y-%m-%d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "87003c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterateThroughDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "393031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Links.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
